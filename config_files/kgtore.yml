experiment:
  backend: pytorch
  dataset: facebook_book
  data_config:
#    strategy: dataset
#    dataset_path: ../data/{0}/dataset.tsv
    strategy: fixed
    train_path: ../data/{0}/dataset.tsv
    test_path: ../data/{0}/dataset.tsv
    side_information:
      - dataloader: KGTORETSVLoader
        attributes: ../data/{0}/kgtore/kg.tsv
#        entities: ../data/{0}/mov/toyentities.tsv
#  prefiltering:
#    strategy: iterative_k_core
#    core: 5
#  splitting:
#    save_on_disk: True
#    save_folder: ../data/{0}/split/
#    test_splitting:
#      strategy: random_subsampling
#      test_ratio: 0.2
  top_k: 10  #10
  gpu: -1
  external_models_path: ../external/models/__init__.py
  evaluation:
    cutoffs: [10]  #10
    simple_metrics: [nDCGRendle2020, nDCG, HR, Precision, Recall, MAP, MRR, ItemCoverage, UserCoverage, NumRetrieved, UserCoverage, Gini, SEntropy, EFD, EPC]
    relevance_threshold: 3
  models:
    external.KGTORE:
      meta:
        hyper_max_evals: 10
        hyper_opt_alg: tpe
        validation_metric: HR
        verbose: True
        save_weights: False
        save_recs: False
        validation_rate: 20
        restore: False
      lr: [ loguniform, -8.90775527898, -6.90775527898 ]
      epochs: 400
      factors: 64
      batch_size: 256
      l_w: [ loguniform, -16.11809565095, -2.30258509299]  # [ quniform, 10e-5, 10, 100 ]
      n_layers: [ quniform, 2, 3, 1 ]
      npr: 10
      criterion: entropy
      loader: KGTORETSVLoader